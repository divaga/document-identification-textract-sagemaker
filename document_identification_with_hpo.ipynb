{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Identification with Amazon SageMaker Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Train a document identification model using SageMaker Image Classification built in algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data folder structure\n",
    "You need to prepare training data in this following folder structure:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ROOT_FOLDER\n",
    "    \\_ CLASS_1\n",
    "        \\_ file_1\n",
    "        \\_ file_2\n",
    "        \\_ file_n\n",
    "    \\_ CLASS_2\n",
    "    \\_ CLASS_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a zip file for your root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute this only once\n",
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "import cv2\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket=sess.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have same current directory with your notebook\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change this!\n",
    "change this based on your preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'document-identification' # Put your data source folder prefix here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip and process your training data\n",
    "DO THIS FIRST: upload your zip file to same directory with your notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove existing folder, in this example KTP is our root folder\n",
    "!rm -R KTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip your zip file\n",
    "!unzip docs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete existing processing folder\n",
    "This following cell will delete previous processing folder. You don't need to execute this if you are using this notebook for first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm -R document_dataset\n",
    "rm -R document_dataset_augmented\n",
    "rm -R document_dataset_augmented_val\n",
    "rm -R data_recordio\n",
    "rm document-train.lst\n",
    "rm document-val.lst\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHANGE THIS!\n",
    "Change these values based on your class name and your root folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS BASED ON YOUR CLASSES/FOLDER NAME IN ALFABHETICAL ORDER\n",
    "document_type = ['KK', 'KTP', 'PASPOR','SIM']\n",
    "\n",
    "# CHANGE THIS BASED ON YOUR ROOT FOLDER NAME\n",
    "inputBasePath = \"KTP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create temporary dataset for image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$inputBasePath\"\n",
    "\n",
    "mkdir -p document_dataset\n",
    "for i in \"$1\"/*; do\n",
    "    c=`basename $i`\n",
    "    mkdir -p document_dataset/$c\n",
    "    for j in `ls $i/*.jpg | shuf | head -n 25`; do        \n",
    "        mv $j document_dataset/$c/\n",
    "    done\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images augmentation\n",
    "We will perform images augmentation to enrich our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from PIL import Image, ImageEnhance\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation functions\n",
    "\n",
    "def sharpen(img, factor):\n",
    "    enhancer_sharpness = ImageEnhance.Sharpness(img)\n",
    "    return enhancer_sharpness.enhance(factor)\n",
    "\n",
    "def contrast(img, factor):\n",
    "    enhancer_contrast = ImageEnhance.Contrast(img)\n",
    "    return enhancer_contrast.enhance(factor)\n",
    "\n",
    "def rotate(img, degrees):\n",
    "    return img.rotate(degrees)\n",
    "\n",
    "def save(img, path):\n",
    "    return img.save(path, \"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new locations\n",
    "inputBasePath = './document_dataset/'\n",
    "outputBasePath = './document_dataset_augmented/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "rotations = [0,90,270]\n",
    "randContrastMin, randContrastMax = (0.8, 1.2)\n",
    "randSharpenMin, randSharpenMax  = (0.8, 1.2)\n",
    "multiplier = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "for f in document_type:\n",
    "    plist = Path(inputBasePath + f + '/').glob('*.jpg')\n",
    "\n",
    "    outpath = outputBasePath + f + '/' \n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    for path in plist:\n",
    "        i = Image.open( path )\n",
    "\n",
    "        for r in rotations:\n",
    "            \n",
    "            for m in range(multiplier):\n",
    "                \n",
    "                randContrast = random.uniform(randContrastMin, randContrastMax)\n",
    "                randSharpen = random.uniform(randSharpenMin, randSharpenMax)\n",
    "\n",
    "                i = rotate(i, r)\n",
    "                i = contrast(i, randContrast)\n",
    "                i = sharpen(i, randSharpen)\n",
    "                \n",
    "                save(i, outpath + str(uuid.uuid4()) + '.jpg') \n",
    "                print('.', end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new locations, please change inputBasePath to your root folder\n",
    "inputBasePath = './KTP/'\n",
    "outputBasePath = './document_dataset_augmented_val/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "rotations = [0,90,270]\n",
    "randContrastMin, randContrastMax = (0.8, 1.2)\n",
    "randSharpenMin, randSharpenMax  = (0.8, 1.2)\n",
    "multiplier = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "for f in document_type:\n",
    "    plist = Path(inputBasePath + f + '/').glob('*.jpg')\n",
    "\n",
    "    outpath = outputBasePath + f + '/' \n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    for path in plist:\n",
    "        i = Image.open( path )\n",
    "\n",
    "        for r in rotations:\n",
    "            \n",
    "            for m in range(multiplier):\n",
    "                \n",
    "                randContrast = random.uniform(randContrastMin, randContrastMax)\n",
    "                randSharpen = random.uniform(randSharpenMin, randSharpenMax)\n",
    "                i = rotate(i, r)\n",
    "                i = contrast(i, randContrast)\n",
    "                i = sharpen(i, randSharpen)\n",
    "                \n",
    "                save(i, outpath + str(uuid.uuid4()) + '.jpg') \n",
    "                print('.', end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download im2rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        \n",
    "# Tool for creating lst file\n",
    "download('https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lst file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python im2rec.py --list --recursive document-train document_dataset_augmented/\n",
    "python im2rec.py --list --recursive document-val document_dataset_augmented_val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training samples\n",
    "training_count = len(open('document-train.lst').readlines())\n",
    "print(training_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to RecordIO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "recordio_dir = pathlib.Path('./data_recordio')\n",
    "recordio_dir.mkdir(exist_ok=True)\n",
    "shutil.copy('document-train.lst', 'data_recordio/');\n",
    "shutil.copy('document-val.lst', 'data_recordio/');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python im2rec.py --resize 224 --quality 90 --num-thread 16 data_recordio/document-train document_dataset_augmented/\n",
    "!python im2rec.py --resize 224 --quality 90 --num-thread 16 data_recordio/document-val document_dataset_augmented_val/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3\n",
    "Upload the data to the S3 bucket. We do this in multiple channels. Channels are simply directories in the bucket that differentiate between training and validation data.\n",
    "Create these following folders in S3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uploader = sagemaker.s3.S3Uploader()\n",
    "\n",
    "data_path = recordio_dir / 'document-train.rec'\n",
    "\n",
    "data_s3_uri = s3_uploader.upload(\n",
    "    local_path=data_path.as_posix(), \n",
    "    desired_s3_uri=f's3://{bucket}/{prefix}/data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = recordio_dir / 'document-val.rec'\n",
    "\n",
    "data_s3_uri = s3_uploader.upload(\n",
    "    local_path=data_path.as_posix(), \n",
    "    desired_s3_uri=f's3://{bucket}/{prefix}/data/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput( \n",
    "    s3_data=f's3://{bucket}/{prefix}/data/train',\n",
    "    content_type='application/x-recordio',\n",
    "    s3_data_type='S3Prefix',\n",
    "    input_mode='Pipe')\n",
    "\n",
    "val_data = sagemaker.inputs.TrainingInput( \n",
    "    s3_data=f's3://{bucket}/{prefix}/data/val',\n",
    "    content_type='application/x-recordio',\n",
    "    s3_data_type='S3Prefix',\n",
    "    input_mode='Pipe')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': val_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Image Classification Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(document_type)\n",
    "num_training_samples = training_count\n",
    "\n",
    "training_image = sagemaker.image_uris.retrieve('image-classification', sagemaker.Session().boto_region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "Since we don't know optimal hyperparameter, we will directly use HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "imageclassification = sagemaker.estimator.Estimator(training_image, \n",
    "                                                    role, \n",
    "                                                    instance_count=1,\n",
    "                                                    instance_type='ml.p3.8xlarge',\n",
    "                                                    output_path=f's3://{bucket}/{prefix}/data/output', \n",
    "                                                    sagemaker_session=sess)\n",
    "\n",
    "imageclassification.set_hyperparameters(num_layers=18, \n",
    "                                        image_shape='3,224,224',\n",
    "                                        num_classes=num_classes,\n",
    "                                        epochs=30, \n",
    "                                        top_k='2',\n",
    "                                        num_training_samples=num_training_samples,\n",
    "                                        precision_dtype='float32',\n",
    "                                        augmentation_type='crop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set hyperparameter optimization jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime \n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "tuning_job_name = \"document-tuning-job-{}\".format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "\n",
    "hyperparameter_ranges = {'learning_rate': ContinuousParameter(0.00001, 1.0),\n",
    "                         'mini_batch_size': IntegerParameter(16, 64),\n",
    "                         'optimizer': CategoricalParameter(['sgd', 'adam', 'rmsprop', 'nag'])}\n",
    "\n",
    "objective_metric_name = 'validation:accuracy'\n",
    "\n",
    "tuner = HyperparameterTuner(imageclassification, \n",
    "                            objective_metric_name, \n",
    "                            hyperparameter_ranges,\n",
    "                            objective_type='Maximize', \n",
    "                            max_jobs=20, \n",
    "                            max_parallel_jobs=2,\n",
    "                            early_stopping_type='Auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({'train': train_data, 'validation': val_data}, \n",
    "          job_name=tuning_job_name, include_cls_metadata=False)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "tuner_metrics.dataframe().sort_values(['FinalObjectiveValue'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = tuner_metrics.dataframe()['TrainingElapsedTimeSeconds'].sum() / 3600\n",
    "print(\"The total training time is {:.2f} hours\".format(total_time))\n",
    "tuner_metrics.dataframe()['TrainingJobStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy best model from hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier = tuner.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Test\n",
    "You can upload your test image data in same directory with this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "    \n",
    "import cv2\n",
    "\n",
    "\n",
    "#file_name = 'kk1.png'\n",
    "file_name = 'ktp1.png'\n",
    "#file_name = 'ktp2.jpg'\n",
    "#file_name = 'sim.jpg'\n",
    "\n",
    "#resize\n",
    "im = cv2.imread(file_name)\n",
    "im = cv2.resize(im, (600, 400))\n",
    "cv2.imwrite(file_name, im)\n",
    "\n",
    "\n",
    "# display test image\n",
    "from IPython.display import Image, display\n",
    "img = Image(file_name) \n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(file_name, 'rb') as image:\n",
    "    f = image.read()\n",
    "    b = bytearray(f)\n",
    "#ic_classifier.content_type = 'application/x-image'\n",
    "#results = ic_classifier.predict(b)\n",
    "results = ic_classifier.predict(b, initial_args={'ContentType': 'image/jpeg'})\n",
    "prob = json.loads(results)\n",
    "classes = document_type\n",
    "for idx, val in enumerate(classes):\n",
    "    print('%s:%f '%(classes[idx], prob[idx]), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS BASED ON TRAINING DATA INDEX\n",
    "#print(result)\n",
    "import numpy as np\n",
    "\n",
    "index = np.argmax(prob)\n",
    "print(\"Result: label - \" + document_type[index] + \", probability - \" + str(prob[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Publish your endpoint using Lambda + API Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
